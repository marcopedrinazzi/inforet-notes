{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641c8e23",
   "metadata": {},
   "source": [
    "# Introduction to text indexing techniques\n",
    "See the extracted dataset sample [here](https://unimi2013.sharepoint.com/:u:/s/InformationRetrieval/EaL7kid2qzdCmAA8RO-m5iQBsvCl5cuNIdn0rsJN1FUhSg?e=fdXkkB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0dbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19281f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3aca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../text-sample/\"\n",
    "files = [f for f in os.listdir(folder) if f.endswith('.txt')]\n",
    "recipes = []\n",
    "for file in files:\n",
    "    with open(os.path.join(folder, file), 'r') as data:\n",
    "        recipes.append(data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4eb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba88b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenize = lambda text: [x.lower() for x in nltk.word_tokenize(text) if x not in punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdddd88",
   "metadata": {},
   "source": [
    "## Bag of words and Inverted Index\n",
    "The occurrences of words in a corpus can be represented by the *document-term* matrix, a matrix $T^{docs \\times vocabulary}$. Howevere, such a matrix is sparse and has a huge dimensionality. We can address this issue by supporting data structures.\n",
    "\n",
    "**BOW**\n",
    "```\n",
    "doc_id: {w: frequency, ...}\n",
    "```\n",
    "**Inverted Index**\n",
    "```\n",
    "w: [doc_id, ...]\n",
    "```\n",
    "**Rich inverted Index**\n",
    "```\n",
    "w: [(doc_id, position, freq, ...), ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "I = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c146af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(enumerate(recipes))\n",
    "for i, document in tqdm(corpus):\n",
    "    tokens = nltk_tokenize(document.lower())\n",
    "    for token in tokens:\n",
    "        BOW[i][token] += 1\n",
    "        I[token].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(BOW[0].items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(I['couscous'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cf701",
   "metadata": {},
   "source": [
    "### To document-term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a56bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.DataFrame(BOW).fillna(0, inplace=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf36ce",
   "metadata": {},
   "source": [
    "## Word relevance\n",
    "Take the top 5 relevant words for document 0. What problems do you see in there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(BOW[0].items(), key=lambda x: -x[1])[:5], sum(BOW[0].values()))\n",
    "print(sorted(BOW[1].items(), key=lambda x: -x[1])[:5], sum(BOW[1].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e081a",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d6513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd90a82",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722fe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5fcca8e",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6a28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f2088eb",
   "metadata": {},
   "source": [
    "### TfIdf by scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34398175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk_tokenize)\n",
    "X = vectorizer.fit_transform(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.inverse_transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52737899",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0,vocabulary.index('cup')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(enumerate(X[0].toarray()[0]), key=lambda x: -x[1])[:5])\n",
    "print(sorted(enumerate(X[1].toarray()[0]), key=lambda x: -x[1])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(vocabulary[w], s) for w, s in sorted(enumerate(X[0].toarray()[0]), key=lambda x: -x[1])[:5]])\n",
    "print([(vocabulary[w], s) for w, s in sorted(enumerate(X[1].toarray()[0]), key=lambda x: -x[1])[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef73b5",
   "metadata": {},
   "source": [
    "## Vector Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9255402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ced1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad270ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7816d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = pca.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(Xa[:,0], Xa[:,1], alpha=0.4, c='#cccccc')\n",
    "ax.scatter(Xa[0,0], Xa[0,1], alpha=0.9, c='#cc0000', s=100)\n",
    "ax.scatter(Xa[1,0], Xa[1,1], alpha=0.9, c='#0000cc', s=100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a5c11",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035047b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'teriyaki rice'\n",
    "q = vectorizer.transform([query]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pca.transform(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(Xa[:,0], Xa[:,1], alpha=0.4, c='#cccccc')\n",
    "ax.scatter(Xa[0,0], Xa[0,1], alpha=0.9, c='#cc0000', s=100)\n",
    "ax.scatter(Xa[1,0], Xa[1,1], alpha=0.9, c='#0000cc', s=100)\n",
    "ax.scatter(qa[0,0], qa[0,1], alpha=0.9, c='#003300', s=100, marker='s')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51d5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
