{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling with LSI and LDA\n",
    "Using `Gensim` on real datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "from wikisearch.retrieval import WikiDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "In this example, we work on the wikidataset at the **sentence level**. We work on `NOUN` and `PROPN` only and we skip empty sentences after tokenization. The ground truth is given by wikientities (multi-class labeling).\n",
    "\n",
    "### Exercise\n",
    "Wikipages contain multiple entities (links to wikidata entities). Try to use such information to build a ground truth for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda text: [x.lemma_.lower() for x in text if x.pos_ in ['NOUN', 'PROPN', 'VERB', 'ADJ', 'ADV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://island.ricerca.di.unimi.it/~alfio/shared/inforet/wikipeople.json'\n",
    "data = WikiDataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = list(set(data.entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q332528', 'Q587557', 'Q715814']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae36de99286d4ef98b5a7c4732375d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, assignment = [], []\n",
    "for i, doc in tqdm(list(enumerate(data.documents))):\n",
    "    clean_doc = \"\".join([x for x in doc if x not in punctuation and x not in digits])\n",
    "    for sentence in nlp(clean_doc).sents:\n",
    "        tokens = tokenize(sentence)\n",
    "        if len(tokens) > 0:\n",
    "            corpus.append(tokens)\n",
    "            assignment.append(data.entities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59db961f4698470881854ab4fd53f8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, assignment = [], []\n",
    "for i, doc in tqdm(list(enumerate(data.documents))):\n",
    "    clean_doc = \"\".join([x for x in doc if x not in punctuation and x not in digits])\n",
    "    tokens = tokenize(nlp(clean_doc))\n",
    "    if len(tokens) > 0:\n",
    "        corpus.append(tokens)\n",
    "        assignment.append(data.entities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city', 'chemnitz', 'consist', 'neighborhood', 'neighborhood', 'einsiedel', 'euba', 'grüna', 'klaffenbach', 'kleinolbersdorfaltenhain', 'mittelbach', 'röhrsdorf', 'wittgensdorf', 'be', 'same', 'time', 'locality', 'meaning', 'section', 'saxon', 'municipal', 'code', 'neighborhood', 'come', 'wake', 'last', 'incorporation', 'wave', 'formerly', 'independent', 'municipality', 'city', 'chemnitz', 'therefore', 'enjoy', 'special', 'position', 'compare', 'other', 'part', 'city', 'locality', 'have', 'local', 'council', 'depend', 'number', 'inhabitant', 'locality', 'concern', 'comprise', 'member', 'as', 'well', 'chairman', 'same', 'local', 'council', 'be', 'hear', 'important', 'matter', 'concern', 'locality', 'final', 'decision', 'be', 'however', 'incumbent', 'city', 'council', 'city', 'chemnitz', 'official', 'identification', 'district', 'number', 'base', 'following', 'principle', 'start', 'city', 'center', 'neighborhood', 'zentrum', 'schloßchemnitz', 'other', 'part', 'city', 'assign', 'clockwise', 'ascend', 'order', 'tenth', 'place', 'index', 'onedigit', 'award', 'direction', 'city', 'periphery', 'ascend', 'order'] Q2795 Chemnitz (city in Germany)\n"
     ]
    }
   ],
   "source": [
    "example = 345\n",
    "ex_entity = assignment[example]\n",
    "print(corpus[example], ex_entity, data.entity_label[ex_entity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = defaultdict(lambda: 0)\n",
    "for doc in corpus:\n",
    "    for word in doc:\n",
    "        I[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcorpus = []\n",
    "for doc in corpus:\n",
    "    newdoc = [x for x in doc if I[x] > 10]\n",
    "    fcorpus.append(newdoc)\n",
    "corpus = fcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (28, 2)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(['philosopher', 'philosopher', 'ancient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [dictionary.doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = lambda c, d: [(d[x], y) for x, y in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 1),\n",
       " ('tradition', 1),\n",
       " ('when', 1),\n",
       " ('christian', 1),\n",
       " ('gain', 1),\n",
       " ('name', 1),\n",
       " ('accompany', 2),\n",
       " ('experience', 1),\n",
       " ('say', 1),\n",
       " ('state', 1),\n",
       " ('trade', 1),\n",
       " ('islamic', 1),\n",
       " ('career', 1),\n",
       " ('meet', 1),\n",
       " ('god', 1),\n",
       " ('prophet', 1),\n",
       " ('journey', 1),\n",
       " ('muhammad', 2),\n",
       " ('uncle', 1),\n",
       " ('muhammads', 1),\n",
       " ('meccans', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse(C[234], dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LsiModel(C, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = model[C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.interfaces.TransformedCorpus"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.488921782540863),\n",
       " (1, -0.47945759098946195),\n",
       " (2, -0.7082532105642725),\n",
       " (3, -0.2761320117255319),\n",
       " (4, -0.4585511912655323),\n",
       " (5, -0.4690218443442252),\n",
       " (6, 0.2122506047414563),\n",
       " (7, -0.7317228312495568),\n",
       " (8, 1.4331343817028788),\n",
       " (9, 2.0199043964081564)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1241)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = model.get_topics()\n",
    "topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "[('be', 0.59), ('jesus', 0.36), ('lincoln', 0.14), ('napoleon', 0.14), ('have', 0.13), ('churchill', 0.13), ('muhammad', 0.12), ('when', 0.11), ('war', 0.1), ('other', 0.1)] \n",
      "\n",
      "Topic 1\n",
      "[('jesus', 0.82), ('be', -0.24), ('napoleon', -0.16), ('lincoln', -0.14), ('churchill', -0.13), ('john', 0.12), ('war', -0.1), ('matthew', 0.1), ('luke', 0.09), ('god', 0.09)] \n",
      "\n",
      "Topic 2\n",
      "[('napoleon', 0.68), ('be', -0.42), ('french', 0.28), ('army', 0.17), ('jesus', 0.12), ('muhammad', -0.12), ('france', 0.1), ('war', 0.1), ('battle', 0.09), ('aristotle', -0.09)] \n",
      "\n",
      "Topic 3\n",
      "[('lincoln', 0.71), ('muhammad', -0.28), ('napoleon', -0.26), ('abraham', 0.19), ('be', -0.17), ('lincolns', 0.14), ('war', 0.12), ('carrier', 0.1), ('state', 0.09), ('support', 0.09)] \n",
      "\n",
      "Topic 4\n",
      "[('muhammad', 0.69), ('churchill', -0.27), ('lincoln', 0.27), ('be', -0.27), ('muslims', 0.14), ('ibn', 0.13), ('medina', 0.12), ('mecca', 0.12), ('god', 0.11), ('muslim', 0.11)] \n",
      "\n",
      "Topic 5\n",
      "[('churchill', 0.69), ('be', -0.25), ('napoleon', -0.24), ('lincoln', -0.22), ('war', 0.19), ('muhammad', 0.19), ('british', 0.15), ('government', 0.11), ('minister', 0.1), ('aristotle', -0.1)] \n",
      "\n",
      "Topic 6\n",
      "[('caesar', 0.74), ('brutus', 0.2), ('be', -0.2), ('play', 0.2), ('bc', 0.16), ('caesars', 0.15), ('rome', 0.13), ('napoleon', -0.12), ('roman', 0.12), ('pompey', 0.12)] \n",
      "\n",
      "Topic 7\n",
      "[('film', -0.71), ('caesar', 0.18), ('be', 0.16), ('also', -0.13), ('lincoln', 0.12), ('work', -0.11), ('new', -0.1), ('jesus', 0.1), ('university', -0.1), ('aristotle', -0.1)] \n",
      "\n",
      "Topic 8\n",
      "[('university', 0.59), ('film', -0.33), ('leipzig', 0.25), ('aristotle', 0.2), ('studies', 0.17), ('be', -0.14), ('century', 0.13), ('form', 0.12), ('other', 0.12), ('german', 0.11)] \n",
      "\n",
      "Topic 9\n",
      "[('aristotle', 0.51), ('university', -0.36), ('be', -0.19), ('film', -0.18), ('leipzig', -0.16), ('aristotles', 0.16), ('work', 0.15), ('city', -0.14), ('form', 0.14), ('when', 0.13)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topicno in range(10):\n",
    "    print('Topic {}'.format(topicno))\n",
    "    print([(x, round(y, 2)) for x, y in model.show_topic(topicno, topn=10)], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2.104251011335291)\n",
      "(1, -0.7033590056898559)\n",
      "(2, -1.0850356008985789)\n",
      "(3, -0.5002738948153902)\n",
      "(4, -0.6327588829925445)\n",
      "(5, -0.6204359599119935)\n",
      "(6, -0.15175312891704792)\n",
      "(7, -0.5422335503967235)\n",
      "(8, 0.999514744648123)\n",
      "(9, 1.6994713814362343)\n"
     ]
    }
   ],
   "source": [
    "for v in vectors[10]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map a new document on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ['abraham', 'lincoln', 'president']\n",
    "qbow = dictionary.doc2bow(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(777, 1), (1087, 1), (1199, 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model[qbow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19492349, -0.18403036,  0.05077765,  0.9628104 ,  0.3679299 ,\n",
       "       -0.27037442, -0.11135121,  0.06071447, -0.0517115 , -0.04167743])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([y for x, y in v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(C, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_vectors = lda[C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics = lda.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topicno in range(6):\n",
    "    print('Topic {}'.format(topicno))\n",
    "    print([(x, round(y, 2)) for x, y in lda.show_topic(topicno, topn=10)], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words to topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = dictionary.token2id['jesus']\n",
    "lda.get_term_topics(tid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: force words in their top topic only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(lda_topics[:,8], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.token2id['philosopher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.get_term_topics(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2words = defaultdict(lambda: [])\n",
    "words2topic = {}\n",
    "for word, wid in dictionary.token2id.items():\n",
    "    best_t = np.argmax(lda_topics[:,wid])\n",
    "    best_p = lda_topics[best_t,wid]\n",
    "    topic2words[best_t].append((word, best_p))\n",
    "    words2topic[word] = (best_t, best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, words in topic2words.items():\n",
    "    print(topic, [x for x, _ in sorted(words, key=lambda k: -k[1])[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words2topic['french'], words2topic['france'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercize\n",
    "1. Exploit lsi and lda models for query purposes\n",
    "2. Exploit lsi and lda models for clustering\n",
    "3. Compare the results against TfIdf vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
